{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from eofs.standard import Eof\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import time\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define all functions we use later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_linear_to_2D(data, side_length = 9):\n",
    "    \"\"\"Transforms an array of the shape (timesteps, number_grid_p) into (timesteps, sqrt(number_grid_p),sqrt(number_grid_p))\"\"\"\n",
    "    t_length, linear_length = data.shape\n",
    "    assert linear_length == side_length**2\n",
    "    \n",
    "    reshaped_data = np.reshape(data,(t_length,side_length,side_length), order = 'F')\n",
    "    return reshaped_data\n",
    "\n",
    "def trans_2D_into_linear(data):\n",
    "    \"\"\"Transforms an array of the shape (timesteps, sqrt(number_grid_p),sqrt(number_grid_p)) into (timesteps, number_grid_p)\"\"\"\n",
    "    t_length, side_length, side_length_y= data.shape\n",
    "    assert side_length == side_length_y\n",
    "    reshaped_data = np.reshape(data,(t_length,side_length**2),order = 'F')\n",
    "    \n",
    "    return reshaped_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(eofs, pcs):\n",
    "    \"\"\"Function that reconstructs Fields from EOF and PC\"\"\"\n",
    "    time_length, spatial_length = pcs.shape\n",
    "    reconstructed_field = np.zeros(pcs.shape)\n",
    "    \n",
    "    for i in range(time_length):\n",
    "        reconstructed_field[i,:] = np.sum(eofs*pcs[i,:,None], axis =0)\n",
    "    return reconstructed_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eofs(eof_rawdata):\n",
    "    \"\"\"Do EOF analysis and give out Eof, PC and corresponding variance\"\"\"\n",
    "    solver = Eof(eof_rawdata,weights=None)\n",
    "    eofs = solver.eofs()\n",
    "    variance_fraction = solver.varianceFraction()\n",
    "    pcs = solver.pcs()\n",
    "    pseudo_pcs = solver.projectField(eof_rawdata)\n",
    "    return eofs, pseudo_pcs, variance_fraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc_poly_extrapolation(pcs, polydegree, times, newtimes):\n",
    "    \"\"\"Polynomial extrapolation of pcs function\"\"\"\n",
    "    pcs_extra = []\n",
    "    diagnostics = []\n",
    "    # polyft for pcs\n",
    "    for i, pc in enumerate(pcs):\n",
    "        output = np.polyfit(times, pc, polydegree, full=True)\n",
    "        coefficients = output[0]\n",
    "        pc_fitted = np.polyval(coefficients, newtimes)\n",
    "        pcs_extra.append(pc_fitted)\n",
    "        diagnostics.append(output[1:]) \n",
    "    return pcs_extra, diagnostics\n",
    "\n",
    "\n",
    "def poly_residuals(pcs, pcs_fitted):\n",
    "    residuals_arrays = []\n",
    "    for pcs, pcsfit in zip(pcs, pcs_fitted):\n",
    "        res = pcsfit[:len(pcs)] - pcs\n",
    "        residuals_arrays.append(res)\n",
    "\n",
    "    return residuals_arrays\n",
    "\n",
    "def autocorrelations(residuals):\n",
    "    autocorrs = []\n",
    "    for res in residuals:\n",
    "        result = np.correlate(np.array(res), np.array(res), mode='full')\n",
    "        length = math.ceil(len(result)/2)\n",
    "        autocorrelation = result[:length]\n",
    "        autocorrs.append(autocorrelation)\n",
    "    return autocorrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_pandas=pd.read_csv('velocity_x.csv')\n",
    "v_y_pandas=pd.read_csv('velocity_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x=v_x_pandas.values[:,1:]\n",
    "v_y=v_y_pandas.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_2D = trans_linear_to_2D(v_x)\n",
    "v_y_2D = trans_linear_to_2D(v_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltimes = np.arange(v_x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot video of velocity field time development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = 3000\n",
    "tstop = 3100\n",
    "tstep = 50\n",
    "var = v_y_2D\n",
    "# defines field and time vector\n",
    "trange = slice(tstart, tstop + 1, tstep)\n",
    "tsteps = alltimes[trange]\n",
    "field=var[trange, :, :]\n",
    "# first plot\n",
    "vmax = np.nanmax(field)\n",
    "vmin = np.nanmin(field)\n",
    "levels = np.linspace(vmin, vmax, 256)\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "cs = ax.contourf(field[0])\n",
    "cbar = plt.colorbar(cs)\n",
    "# display video\n",
    "for i, f in enumerate(field):\n",
    "    ax.collections = []\n",
    "    cs = ax.contourf(f)\n",
    "    plt.title(\"t = %s\" % (tsteps[i]))    \n",
    "    IPython.display.display(fig)\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U and V Seperated analysed in 1D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eofs_x, pcs_x, variance_x = get_eofs(v_x)\n",
    "eofs_y, pcs_y, variance_y = get_eofs(v_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2D Analysis**, is not necessary, we demonstrate, that it does not matter if we do it in 2D or 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eofs_x_2D, pcs_x_2D, variance_x_2D = get_eofs(v_x_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(variance_x_2D)\n",
    "plt.plot(variance_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_eofs_x_2D = trans_2D_into_linear(eofs_x_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(eofs_x[0,:])\n",
    "plt.plot(trans_eofs_x_2D[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**, Can perfectly reconstruct field, and EoFs are orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_field_fun = reconstruct(eofs_x, pcs_x)\n",
    "t_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(v_x[t_step,:], label = \"act. field\")\n",
    "plt.plot(reconstructed_field_fun[t_step,:], label = \"My rec\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test of Orthogonality\n",
    "for j in range(81):\n",
    "    for i in range(81):\n",
    "        diag_sum = np.sum(eofs_x[j,:]*eofs_x[i,:])\n",
    "        if diag_sum>1e-14:\n",
    "            print(diag_sum, i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polyfit extrapolation of weights of pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastart = -200\n",
    "datastop = None\n",
    "extratime = 101\n",
    "pcs_for_fit = slice(0, 81)\n",
    "polydegree = 3\n",
    "\n",
    "datapoints_for_fit = slice(datastart, datastop)\n",
    "times = alltimes[datapoints_for_fit]\n",
    "newtimes = np.arange(times[0], times[-1] + extratime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_x_forfit = np.transpose(pcs_x[datapoints_for_fit, pcs_for_fit])\n",
    "pcs_y_forfit = np.transpose(pcs_y[datapoints_for_fit, pcs_for_fit])\n",
    "\n",
    "pcs_x_extra, diagnostics_x = pc_poly_extrapolation(pcs_x_forfit, polydegree, times, newtimes)\n",
    "pcs_y_extra, diagnostics_y = pc_poly_extrapolation(pcs_y_forfit, polydegree, times, newtimes)\n",
    "\n",
    "# diagnostics: residuals, rank, singular values, conditioning threshold\n",
    "residuals_x = [dia[0] for dia in diagnostics_x]\n",
    "mse_x = [list(res).pop() for res in residuals_x]\n",
    "residuals_y = [dia[0] for dia in diagnostics_y]\n",
    "mse_y = [list(res).pop() for res in residuals_y]\n",
    "# print(residuals_x, residuals_y) # sum of the squares of the fit errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the residuals of polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_x_arrays = poly_residuals(pcs_x_forfit, pcs_x_extra)\n",
    "residuals_y_arrays = poly_residuals(pcs_y_forfit, pcs_y_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrs_x = autocorrelations(residuals_x_arrays)\n",
    "autocorrs_y = autocorrelations(residuals_y_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only first x pcs\n",
    "showplots = slice(0, 5)\n",
    "i = 1\n",
    "for pc, pc_extra, residuals, autocorr, pcleft in zip(pcs_x_forfit[showplots], pcs_x_extra[showplots], \n",
    "                                   residuals_x_arrays[showplots], autocorrs_x[showplots], np.transpose(pcs_x[:, showplots])):\n",
    "    fig = plt.figure(dpi=100)\n",
    "    plt.plot(newtimes, pc_extra)\n",
    "    plt.plot(alltimes[datastart:], pcleft[datastart:])\n",
    "    plt.plot(times, pc)\n",
    "    plt.title(\"Extrapolation of weights: pc %s\" %i)\n",
    "    fig = plt.figure(dpi=100)\n",
    "    plt.plot(times, residuals)\n",
    "    plt.title(\"Residuals: pc %s\" %i)\n",
    "    fig = plt.figure(dpi=100)\n",
    "    plt.hist(residuals)\n",
    "    plt.title(\"Residuals: pc %s\" %i)\n",
    "    fig = plt.figure(dpi=100)\n",
    "#     plt.plot(autocorr)\n",
    "    plt.xcorr(residuals, residuals, maxlags=100)\n",
    "    plt.title(\"Autocorrelation: pc %s\" %i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction time steps we pick \n",
    "prediction_times = [25, 50, 75]\n",
    "pcs_prediction_x = []\n",
    "pcs_prediction_y = []\n",
    "for pcx, pcy in zip(pcs_x_extra, pcs_y_extra):\n",
    "    pcs_prediction_x.append(pcx[prediction_times])\n",
    "    pcs_prediction_y.append(pcy[prediction_times])\n",
    "pcs_prediction_x = np.transpose(pcs_prediction_x)\n",
    "pcs_prediction_y = np.transpose(pcs_prediction_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_xplus = np.array([pred + mse_x for pred in pcs_prediction_x])\n",
    "var_xminus = np.array([pred - mse_x for pred in pcs_prediction_x])\n",
    "var_yplus = np.array([pred + mse_y for pred in pcs_prediction_y])\n",
    "var_yminus = np.array([pred - mse_y for pred in pcs_prediction_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_sum_x = np.sqrt(np.sum(np.array(mse_x)**2))\n",
    "mse_sum_y = np.sqrt(np.sum(np.array(mse_y)**2))\n",
    "print(mse_sum_x)\n",
    "print(mse_sum_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct predicted field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x = reconstruct(eofs_x, pcs_prediction_x)\n",
    "predicted_y = reconstruct(eofs_y, pcs_prediction_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2D_x = trans_linear_to_2D(predicted_x)\n",
    "predicted_2D_y = trans_linear_to_2D(predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct with variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_var_xplus = reconstruct(eofs_x, var_xplus)\n",
    "predicted_var_xminus = reconstruct(eofs_x, var_xminus)\n",
    "predicted_var_yplus = reconstruct(eofs_y, var_yplus)\n",
    "predicted_var_yminus = reconstruct(eofs_y, var_yminus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2D_var_xplus = trans_linear_to_2D(predicted_var_xplus)\n",
    "predicted_2D_var_xminus = trans_linear_to_2D(predicted_var_xminus)\n",
    "predicted_2D_var_yplus = trans_linear_to_2D(predicted_var_yplus)\n",
    "predicted_2D_var_yminus = trans_linear_to_2D(predicted_var_yminus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last time step data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3), dpi=200)\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.contourf(v_x_2D[-1, :, :])\n",
    "plt.colorbar()\n",
    "plt.axis(\"scaled\")\n",
    "plt.title(\"Velocity u\")\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.contourf(v_y_2D[-1, :, :])\n",
    "plt.title(\"Velocity v\")\n",
    "plt.colorbar()\n",
    "plt.axis(\"scaled\")\n",
    "plt.suptitle(\"Last data time step\")\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, predtime in enumerate(prediction_times):\n",
    "    fig = plt.figure(figsize=(8, 3), dpi=200)\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.contourf(predicted_2D_x[i, :, :])\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.title(\"Velocity u\")\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.contourf(predicted_2D_y[i, :, :])\n",
    "    plt.title(\"Velocity v\")\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.suptitle(\"Prediction at time step %s\" %predtime)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of prediction time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, predtime in enumerate(prediction_times):\n",
    "    fig = plt.figure(figsize=(8, 3), dpi=200)\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.contourf(predicted_2D_var_xminus[i, :, :])\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.title(\"Velocity u - MSE\")\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.contourf(predicted_2D_var_xplus[i, :, :])\n",
    "    plt.title(\"Velocity u + MSE\")\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.suptitle(\"Variance velocity u at time step %s\" %predtime)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, predtime in enumerate(prediction_times):\n",
    "    fig = plt.figure(figsize=(8, 3), dpi=200)\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.contourf(predicted_2D_var_yminus[i, :, :])\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.title(\"Velocity v - MSE\")\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.contourf(predicted_2D_var_yplus[i, :, :])\n",
    "    plt.title(\"Velocity v + MSE\")\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.suptitle(\"Variance velocity v at time step %s\" %predtime)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_times2 = [alltimes[-1] + 25, alltimes[-1] + 50, alltimes[-1] + 75]\n",
    "pd.DataFrame(predicted_x,index=prediction_times2).to_csv(\"velocity_x_prediction.csv\")\n",
    "pd.DataFrame(predicted_y,index=prediction_times2).to_csv(\"velocity_y_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"velocity_y_prediction_varminus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
